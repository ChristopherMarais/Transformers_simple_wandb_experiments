{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c694156-20c6-4e0a-bfb0-a0e3e0c144eb",
   "metadata": {},
   "source": [
    "# Parameter tuning\n",
    "\n",
    "This script is to tune the parameters of a model and test different parameters.\n",
    "\n",
    "To test different models and types (BERT, GPT2, XLNet, ...) it can be changed in the MultiLabelClassificationModel function as descibed in the [Simple transformers docs](https://simpletransformers.ai/docs/installation/). \n",
    "\n",
    "### SDG classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee564013-69a3-4853-98fe-6c2a00844ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T15:02:14.439080Z",
     "iopub.status.busy": "2022-08-26T15:02:14.439080Z",
     "iopub.status.idle": "2022-08-26T15:02:19.004641Z",
     "shell.execute_reply": "2022-08-26T15:02:19.003639Z",
     "shell.execute_reply.started": "2022-08-26T15:02:14.439080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define imports\n",
    "import wandb\n",
    "import torch\n",
    "import sklearn\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43217174-039a-41fa-9ab1-0441bc061dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T15:02:19.006621Z",
     "iopub.status.busy": "2022-08-26T15:02:19.006621Z",
     "iopub.status.idle": "2022-08-26T15:02:19.036621Z",
     "shell.execute_reply": "2022-08-26T15:02:19.035623Z",
     "shell.execute_reply.started": "2022-08-26T15:02:19.006621Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see GPU avaialability\n",
    "cuda_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2410685e-4550-4080-aa6b-74b1cce94dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T15:02:19.037622Z",
     "iopub.status.busy": "2022-08-26T15:02:19.037622Z",
     "iopub.status.idle": "2022-08-26T15:02:19.926625Z",
     "shell.execute_reply": "2022-08-26T15:02:19.925625Z",
     "shell.execute_reply.started": "2022-08-26T15:02:19.037622Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% PER CLASS:\n",
      "\n",
      " SDG1      5.354267\n",
      "SDG2      5.152979\n",
      "SDG3      7.447665\n",
      "SDG4      4.388084\n",
      "SDG5      4.186795\n",
      "SDG6      5.314010\n",
      "SDG7      5.756844\n",
      "SDG8      6.400966\n",
      "SDG9      5.636071\n",
      "SDG10     5.152979\n",
      "SDG11     5.354267\n",
      "SDG12     5.112721\n",
      "SDG13    10.265700\n",
      "SDG14     4.830918\n",
      "SDG15     5.676329\n",
      "SDG16     4.951691\n",
      "SDG17     9.017713\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('OneHot_Combined_cln_utf8.tsv', sep='\\t')\n",
    "data = data.iloc[-1000:,:] # only use a subset of the data \n",
    "\n",
    "# reformat data\n",
    "sdg_lst = ['SDG1','SDG2','SDG3','SDG4','SDG5','SDG6','SDG7','SDG8','SDG9','SDG10','SDG11','SDG12','SDG13','SDG14','SDG15','SDG16','SDG17']\n",
    "data['y'] = data[sdg_lst].values.tolist()\n",
    "y = data['y']\n",
    "X = data['abstract']\n",
    "\n",
    "# plot ratio of data\n",
    "class_weight = (data[sdg_lst].sum()/ data[sdg_lst].sum().sum())\n",
    "print('% PER CLASS:\\n\\n', class_weight*100)\n",
    "data[sdg_lst].sum().plot.bar()\n",
    "\n",
    "# split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# add data to dataframes\n",
    "train_df = pd.DataFrame()\n",
    "train_df['text'] = X_train\n",
    "train_df['labels'] = y_train\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "eval_df = pd.DataFrame()\n",
    "eval_df['text'] = X_val\n",
    "eval_df['labels'] = y_val\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# get number of classes\n",
    "label_count = len(sdg_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab116e8c-6382-48c5-b23d-bc7b3553c389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T15:02:19.943635Z",
     "iopub.status.busy": "2022-08-26T15:02:19.942638Z",
     "iopub.status.idle": "2022-08-26T15:02:22.958161Z",
     "shell.execute_reply": "2022-08-26T15:02:22.957156Z",
     "shell.execute_reply.started": "2022-08-26T15:02:19.943635Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 7o7g867l\n",
      "Sweep URL: https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/7o7g867l\n"
     ]
    }
   ],
   "source": [
    "# create function for creating layer learning rate dictionary\n",
    "# this is used for freezing the number of layers from the first layer -> x layer\n",
    "def create_custom_layer_dict_lst(x):    \n",
    "    # get list of number of layers\n",
    "    # layers_lst = [0]\n",
    "    # for i in model.get_named_parameters():\n",
    "    #     layers_lst.append(int(re.findall(r\"layer\\.(\\d+)\", i)[0]))\n",
    "    #     layers_lst = list(set(layers_lst))\n",
    "    # create dictionary of \n",
    "    layer_dict_lst = []\n",
    "    for i in range(x+1):\n",
    "        layer_dict_lst.append({'layer':i, 'lr':0.0})\n",
    "    return layer_dict_lst\n",
    "\n",
    "# Define the sweep config. \n",
    "# this defines the parameters that will be searched when performing parameter optimisation\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  # bayes, grid, random\n",
    "    \"metric\": {\"name\": \"accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"num_train_epochs\": {\"min\": 1, \"max\": 5},\n",
    "        \"learning_rate\": {\"min\": 5e-5, \"max\": 4e-4},\n",
    "        \"train_batch_size\":{\"min\": 1, \"max\": 30},\n",
    "        \"eval_batch_size\":{\"min\": 1, \"max\": 30},\n",
    "        \"warmup_steps\":{\"min\": 50, \"max\": 500},\n",
    "        \"weight_decay\":{\"min\": 0.01, \"max\": 0.1},\n",
    "        # \"logging_steps\":{\"min\": 1, \"max\": 20}, #{\"values\": [2, 5, 10]}\n",
    "        \"threshold\":{\"min\":0.0, \"max\":1.0},\n",
    "        'custom_layer_parameters':{\"values\": [create_custom_layer_dict_lst(0), create_custom_layer_dict_lst(6), create_custom_layer_dict_lst(8)]}\n",
    "    },\n",
    "}\n",
    "\n",
    "# define the project and entity under which the outputs will be recorded in wandb\n",
    "sweep_id = wandb.sweep(sweep_config, entity='sasdghub', project=\"sasdghub_ml_classify\")\n",
    "\n",
    "# Set logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f3c1a9-502b-42df-93c1-d958d7df4a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T15:02:19.927616Z",
     "iopub.status.busy": "2022-08-26T15:02:19.927616Z",
     "iopub.status.idle": "2022-08-26T15:02:19.941649Z",
     "shell.execute_reply": "2022-08-26T15:02:19.940622Z",
     "shell.execute_reply.started": "2022-08-26T15:02:19.927616Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create functions for additional evaluation outputs\n",
    "def acc_result(true, pred):\n",
    "    print(true, pred)\n",
    "    true=np.argmax(true, axis=1)\n",
    "    print('______________')\n",
    "    pred=np.argmax(pred, axis=1)\n",
    "    print(true, pred)\n",
    "    acc = sklearn.metrics.accuracy_score(true, pred)\n",
    "    return acc\n",
    "\n",
    "def f1_macro_result(true, pred):\n",
    "    true=np.argmax(true, axis=1)\n",
    "    pred=np.argmax(pred, axis=1)\n",
    "    f1 = sklearn.metrics.f1_score(true, pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "def f1_micro_result(true, pred):\n",
    "    true=np.argmax(true, axis=1)\n",
    "    pred=np.argmax(pred, axis=1)\n",
    "    f1 = sklearn.metrics.f1_score(true, pred, average='micro')\n",
    "    return f1\n",
    "\n",
    "def cm_result(true, pred):\n",
    "    true=np.argmax(true, axis=1)\n",
    "    pred=np.argmax(pred, axis=1)\n",
    "    cm = wandb.plot.confusion_matrix(probs=None, y_true=true, preds=pred, class_names=sdg_lst) #sklearn.metrics.multilabel_confusion_matrix(true, pred)\n",
    "    return cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eda9b5-fdb4-4cc5-88d7-ad52fee899a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-26T15:02:22.959172Z",
     "iopub.status.busy": "2022-08-26T15:02:22.959172Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wandb.agents.pyagent:Starting sweep agent: entity=None, project=None, count=None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3njx1x77 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcustom_layer_parameters: [{'layer': 0, 'lr': 0}]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_batch_size: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00011788752468989662\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tthreshold: 0.15365589975095395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 22\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 54\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.040794985521082905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m (\u001b[33msasdghub\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\Transformers_simple_wandb_experiments\\SASDGHUB\\wandb\\run-20220826_110226-3njx1x77</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/3njx1x77\" target=\"_blank\">cerulean-sweep-1</a></strong> to <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/7o7g867l\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/7o7g867l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForMultiLabelSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForMultiLabelSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4627b7219b6f41fb9ae6303eee9a7d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_xlnet_128_0_2\n",
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1932b2dece4d288dec840f3df00425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85c0b041fd04ca5b6c8176df8dfa231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf14618fce9413da0226db4f9cf8c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.15074082 0.10800835 0.12833568 ... 0.09872892 0.08126572 0.14629602]\n",
      " [0.15129226 0.13368124 0.10297403 ... 0.10832281 0.07549447 0.11588177]\n",
      " [0.15049562 0.10373033 0.11965332 ... 0.09319461 0.07864414 0.14152946]\n",
      " ...\n",
      " [0.15279268 0.12003568 0.14191523 ... 0.08817415 0.08407428 0.11439019]\n",
      " [0.17402062 0.15718393 0.10829459 ... 0.11447064 0.08469793 0.14329906]\n",
      " [0.20602146 0.18153727 0.14407729 ... 0.14140508 0.1199083  0.20998001]]\n",
      "______________\n",
      "[14  3  6 14  1 15 14 13  2  5  1  8  7  8  5  3  7  2  3  8 11 16  0 14\n",
      " 12 16  4 10  3  6  0 15  9 11  5  0  7  7  3 13  0  9 12  8  8  6  3  7\n",
      "  4  2 10  2  7  1 16 12  5 16  5  1 12  6 16  0 10 12 16  2  6 16  0 10\n",
      " 13  7  0  8  6  0 12  0 16  0 11 12 13  7  4  0  2 11 14  6 14  6 14  4\n",
      "  6  0  0  2  2 12  5  9  6 15  1  7  6  3 14  2  2  1 12  4  6  8 15  7\n",
      "  2  3 16 16  1  2  6  5  2  0  5  2  0  3 14  0  0  6 12 14  0  1  7  2\n",
      "  2  3  1  0 14  6 14  4  8  3  5  7  0  0  3  2  1  9  3  4  2  5  1  9\n",
      " 15 11  0  9  6 10 10  0  4 13  0 14 11  7  2 14  2  3 12  8  5 15  6  2\n",
      " 10  0 12  1  0  1  1 11 15 15 15  0  2  2  7  3 11  2  1  2  3  2  9 12\n",
      "  1  5  3 11  0  0  8  1  2  4 16  9  3 15  0  0  9 15 13  0  7  7  6 12\n",
      " 16  0 13  0  0  7  3  5  6 16  0 10  0  2  0 10 13  3  3  1  0  7  1  0\n",
      " 12  2  8  8  2 14 10  2  3  0 14  7  5  9  0  4 10  0  0  6  0  3  3  6\n",
      " 14  6  6  0 11  7  1  8  5  3 12  3] [0 3 0 0 0 0 0 6 2 9 3 3 3 3 1 3 9 3 3 3 3 9 3 0 9 9 9 3 3 3 9 9 0 0 3 9 3\n",
      " 0 3 3 9 9 3 3 3 3 3 0 3 2 0 3 9 0 9 9 2 9 9 3 3 3 3 3 0 3 0 3 3 3 3 3 4 3\n",
      " 9 9 0 9 3 9 3 9 9 3 9 3 3 0 0 9 3 0 2 9 0 3 0 3 9 3 0 3 3 9 0 0 0 3 3 3 0\n",
      " 3 3 3 3 2 3 3 0 9 3 3 3 3 3 3 2 2 3 3 2 3 9 3 3 3 9 3 9 3 9 9 3 9 3 3 3 9\n",
      " 3 3 0 3 3 0 3 0 3 0 9 3 3 3 0 0 3 0 3 0 9 9 3 3 3 3 0 3 9 3 3 3 0 0 9 0 3\n",
      " 9 0 3 3 3 3 3 0 9 9 0 3 9 3 9 9 0 3 0 3 0 9 3 0 3 9 9 3 2 0 9 0 9 3 3 9 0\n",
      " 3 9 3 3 3 9 3 0 9 3 0 0 9 9 9 3 9 0 9 9 0 3 9 3 3 9 0 9 9 3 3 3 3 9 0 3 3\n",
      " 9 3 0 9 9 9 3 3 3 0 3 0 9 3 9 0 9 3 0 9 3 0 3 3 3 3 0 3 0 9 3 3 3 0 0 3 0\n",
      " 3 0 3 9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:simpletransformers.classification.classification_model:can't log value of type: <class 'wandb.viz.CustomChart'> to tensorboar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec3112f7d644f27899c1e1e74d6167e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 4:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482c437d2cd645c8b7830324269431ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.10737841 0.09835768 0.08004999 ... 0.14265668 0.06756335 0.0483471 ]\n",
      " [0.17665462 0.06390736 0.17714851 ... 0.03912333 0.1885713  0.05339189]\n",
      " [0.10281806 0.04621022 0.0557447  ... 0.05407163 0.05238088 0.06810941]\n",
      " ...\n",
      " [0.13684709 0.05664449 0.16436321 ... 0.03153871 0.12540297 0.03172353]\n",
      " [0.26139197 0.19504191 0.13215642 ... 0.24915691 0.22164483 0.33654052]\n",
      " [0.27775761 0.21950416 0.23972848 ... 0.29552472 0.34771416 0.54425997]]\n",
      "______________\n",
      "[14  3  6 14  1 15 14 13  2  5  1  8  7  8  5  3  7  2  3  8 11 16  0 14\n",
      " 12 16  4 10  3  6  0 15  9 11  5  0  7  7  3 13  0  9 12  8  8  6  3  7\n",
      "  4  2 10  2  7  1 16 12  5 16  5  1 12  6 16  0 10 12 16  2  6 16  0 10\n",
      " 13  7  0  8  6  0 12  0 16  0 11 12 13  7  4  0  2 11 14  6 14  6 14  4\n",
      "  6  0  0  2  2 12  5  9  6 15  1  7  6  3 14  2  2  1 12  4  6  8 15  7\n",
      "  2  3 16 16  1  2  6  5  2  0  5  2  0  3 14  0  0  6 12 14  0  1  7  2\n",
      "  2  3  1  0 14  6 14  4  8  3  5  7  0  0  3  2  1  9  3  4  2  5  1  9\n",
      " 15 11  0  9  6 10 10  0  4 13  0 14 11  7  2 14  2  3 12  8  5 15  6  2\n",
      " 10  0 12  1  0  1  1 11 15 15 15  0  2  2  7  3 11  2  1  2  3  2  9 12\n",
      "  1  5  3 11  0  0  8  1  2  4 16  9  3 15  0  0  9 15 13  0  7  7  6 12\n",
      " 16  0 13  0  0  7  3  5  6 16  0 10  0  2  0 10 13  3  3  1  0  7  1  0\n",
      " 12  2  8  8  2 14 10  2  3  0 14  7  5  9  0  4 10  0  0  6  0  3  3  6\n",
      " 14  6  6  0 11  7  1  8  5  3 12  3] [13  3  6 13  2  4 13 13  2 12  2 12  3  7 13  3 16  2  3 12  7 16 16 13\n",
      " 16 16 16 10  3  5 16 16  7  7 12 16  7  5  4 12 16 12 12  7 12 12  3  3\n",
      "  4  2 10  2 13  2 16 12  5 16 12  7 12  6  5 15 10 12  7  2 12  7 12  3\n",
      "  5  3 16 16 10 16  5 16 16 16 12 12 12  3  2  0  2 16 13  5 13 16  2  4\n",
      "  5 12 16 12  2 12 10 16  5 15 13  7  5  3 13  2 10  2 16  2 12 10  4 16\n",
      "  2  5 12 16 12  2  5  2  2 10  5  2 16  3 12 12 16 12 12 12 16 12  7 16\n",
      "  2  3  7 16 13 12  5  2  7  3 12  7 12  0 16  2  2  3  3  4  2  2 12  7\n",
      " 16 16 12  0 12  5 10 16 12 13 12 12  7  3 12 13  2 16 12 16 12  3 13  2\n",
      " 10 16 12  2 12 16  2 16 15  4 15  3  2  2  5  3  5  2 12 16  3  2  3 16\n",
      "  2 12 15 13 16  0 10 12  2 16  7 16  7 15 16  7  3  0 12 16 16  7 12 12\n",
      " 16 12 13  7 16 16  3 16 12 16 16 10  7  2  5 12 13  3  3 12  0  7 12 16\n",
      " 12  2 12 12  2 12 10  2  3 16 13 16 12 15 16  4  5 12 16 12 12  3  3  6\n",
      " 12  6  6  3  7  7 12  3  5  3 12 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:simpletransformers.classification.classification_model:can't log value of type: <class 'wandb.viz.CustomChart'> to tensorboar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556c6470f4ac43b399dc042acf19953c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 4:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4255b2efc347eebb95e14f1f3fa4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.06183357 0.10072976 0.03606831 ... 0.44268617 0.05077612 0.05393963]\n",
      " [0.10934497 0.05781191 0.09119074 ... 0.03379278 0.11139835 0.05016713]\n",
      " [0.04153882 0.02551926 0.05911923 ... 0.02860218 0.0628233  0.07540954]\n",
      " ...\n",
      " [0.10519162 0.05929251 0.06954959 ... 0.02927377 0.10435936 0.04045238]\n",
      " [0.05776541 0.05438543 0.03109751 ... 0.04427903 0.04758471 0.16094796]\n",
      " [0.16725042 0.07738316 0.09953874 ... 0.09041094 0.17179678 0.22921947]]\n",
      "______________\n",
      "[14  3  6 14  1 15 14 13  2  5  1  8  7  8  5  3  7  2  3  8 11 16  0 14\n",
      " 12 16  4 10  3  6  0 15  9 11  5  0  7  7  3 13  0  9 12  8  8  6  3  7\n",
      "  4  2 10  2  7  1 16 12  5 16  5  1 12  6 16  0 10 12 16  2  6 16  0 10\n",
      " 13  7  0  8  6  0 12  0 16  0 11 12 13  7  4  0  2 11 14  6 14  6 14  4\n",
      "  6  0  0  2  2 12  5  9  6 15  1  7  6  3 14  2  2  1 12  4  6  8 15  7\n",
      "  2  3 16 16  1  2  6  5  2  0  5  2  0  3 14  0  0  6 12 14  0  1  7  2\n",
      "  2  3  1  0 14  6 14  4  8  3  5  7  0  0  3  2  1  9  3  4  2  5  1  9\n",
      " 15 11  0  9  6 10 10  0  4 13  0 14 11  7  2 14  2  3 12  8  5 15  6  2\n",
      " 10  0 12  1  0  1  1 11 15 15 15  0  2  2  7  3 11  2  1  2  3  2  9 12\n",
      "  1  5  3 11  0  0  8  1  2  4 16  9  3 15  0  0  9 15 13  0  7  7  6 12\n",
      " 16  0 13  0  0  7  3  5  6 16  0 10  0  2  0 10 13  3  3  1  0  7  1  0\n",
      " 12  2  8  8  2 14 10  2  3  0 14  7  5  9  0  4 10  0  0  6  0  3  3  6\n",
      " 14  6  6  0 11  7  1  8  5  3 12  3] [14  3  6 14  1  4 14 13  2  5  2 12  3  7  5  3 16  2  3 12 11 16  0 14\n",
      " 12 16 16 10  3  1 16 15  9 11  5 16  7  3  4 13 16 12 13  0  6 12  3  7\n",
      "  4  2 10  2 13  2 16 12  5 16  5  1 12  6  2  0 10 12  7  2  6 16 10 10\n",
      " 10  7  0 16  6 16 12  2 16 16 13 13 13  7  2  9  2 13 13  6 14  6 13  4\n",
      "  6 12 16  2  2 14 10 16  6 15 14  7 16  3 14  2 10  1 12  4  6 10 15 16\n",
      "  2  3  6 16  2  2  6  5  2 10  5  2 16  3 13  5 16  6 16 14 16  1  7 16\n",
      "  2  3  1 16 13 13 14  4 10  3  5  7 12  0 16  2  1  9  3  4  2  5 12  7\n",
      " 16 13  5 16 12 13 10 16 12 13 12 14  6  7 13 14  2 16 12 16  5 15  5  2\n",
      " 10 16 12  1 13 16  1 16 15 15 15  9  2  2 15  3  5  2  2  2  3  2  9 12\n",
      "  1  5  3 11  3  0 10 12  2 16 16 16  3 15 16  1  9 10 13 16  9  7  6 12\n",
      " 16 13 13 15 16 16  3 16  6 16 16 10  7  2  9 13 13  3  3  1  0  7 12 16\n",
      " 12  2  5  6  2 13 10  2  3 16 14 16  6 15 16  4 10 12  0 12 12  3  3  6\n",
      " 13  6  6 10 11  7  5  6  5  3  6  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:simpletransformers.classification.classification_model:can't log value of type: <class 'wandb.viz.CustomChart'> to tensorboar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdef2e9c69f84238a3234d11a819e540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 4:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e82fffc71f3490db87a4ad3dda9418a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.0518876  0.09662015 0.05559537 ... 0.57510418 0.02870682 0.05130501]\n",
      " [0.07750964 0.0458731  0.06355313 ... 0.02645739 0.04789378 0.04527048]\n",
      " [0.03149243 0.02541135 0.03987177 ... 0.01983227 0.03192921 0.04823245]\n",
      " ...\n",
      " [0.07503084 0.04773756 0.056361   ... 0.02603549 0.04452708 0.04198694]\n",
      " [0.05067112 0.04383947 0.03706966 ... 0.04328064 0.03950184 0.14412674]\n",
      " [0.21417041 0.10781652 0.16465312 ... 0.09600972 0.17346799 0.20837526]]\n",
      "______________\n",
      "[14  3  6 14  1 15 14 13  2  5  1  8  7  8  5  3  7  2  3  8 11 16  0 14\n",
      " 12 16  4 10  3  6  0 15  9 11  5  0  7  7  3 13  0  9 12  8  8  6  3  7\n",
      "  4  2 10  2  7  1 16 12  5 16  5  1 12  6 16  0 10 12 16  2  6 16  0 10\n",
      " 13  7  0  8  6  0 12  0 16  0 11 12 13  7  4  0  2 11 14  6 14  6 14  4\n",
      "  6  0  0  2  2 12  5  9  6 15  1  7  6  3 14  2  2  1 12  4  6  8 15  7\n",
      "  2  3 16 16  1  2  6  5  2  0  5  2  0  3 14  0  0  6 12 14  0  1  7  2\n",
      "  2  3  1  0 14  6 14  4  8  3  5  7  0  0  3  2  1  9  3  4  2  5  1  9\n",
      " 15 11  0  9  6 10 10  0  4 13  0 14 11  7  2 14  2  3 12  8  5 15  6  2\n",
      " 10  0 12  1  0  1  1 11 15 15 15  0  2  2  7  3 11  2  1  2  3  2  9 12\n",
      "  1  5  3 11  0  0  8  1  2  4 16  9  3 15  0  0  9 15 13  0  7  7  6 12\n",
      " 16  0 13  0  0  7  3  5  6 16  0 10  0  2  0 10 13  3  3  1  0  7  1  0\n",
      " 12  2  8  8  2 14 10  2  3  0 14  7  5  9  0  4 10  0  0  6  0  3  3  6\n",
      " 14  6  6  0 11  7  1  8  5  3 12  3] [14  3  6 14  1  4 14 13  2  5  2 12  7  7  5  3 16  2  3 12 11 16  0 14\n",
      " 14  9 16 10 10  1  3 15  9 11  5 16  7  7  4 13 16 12 13 10 12 12  3  7\n",
      "  4  2 10  2 14  2 16 12  5 16  5  1 12  6  9  0 10 12 16  2  6  7 10 10\n",
      " 14  7  0 16  6  7 12  2  0 16 14 13 14  7  2  0  2 14 14  6 14  8 14  4\n",
      "  6 12 16 12  2 14 10 16  6 15 14  7 10  3 14  2 10  1 12  4  6 10 15 16\n",
      " 10  3  6 16 12  2  6  5  2 10  5  2 16  3 13  5 16  6 12 14 16  1  7 16\n",
      "  2  3  1 12 14 13 14  4 10  3  5  7 14  0 16  2  1  9  3  4  2  5 12  7\n",
      " 16 14  5  9 12 11 10  7 12 14  1 14  6  7 14 14  2  7 12 16  5 15  5  2\n",
      " 10 16 12  1 14 12  1 12 15 15 15  9  2  2 15  3  5  2  2 12  3  2  9 12\n",
      "  1  5  7 11  3  0 10 12  2  3 16  7  3 15 12  1  9 15 13 16  9  7 12 12\n",
      " 16 13 13 15 16 16  3  8 12 16  9 10  9  2 16 14 13  3  3  1  0  7 12 16\n",
      " 12  2  5  6  2 13 10  2  3  7 14  9  5  9  7  4 10 12  9 12 14  3  3  6\n",
      " 13  6  6 10 11  7  5  8  5  3 12  3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:simpletransformers.classification.classification_model:can't log value of type: <class 'wandb.viz.CustomChart'> to tensorboar\n",
      "INFO:simpletransformers.classification.classification_model: Training of xlnet model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6d37efbc864a909d360ac2f5e468cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2dfca58ae143199247978278f04d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'LRAP': 0.8532183059021509, 'accuracy': 0.5866666666666667, 'f1_macro': 0.572205070699368, 'f1_micro': 0.5866666666666667, 'cm': <wandb.viz.CustomChart object at 0x00000234001DF6D0>, 'eval_loss': 0.27803556956350806}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.0518876  0.09662015 0.05559537 ... 0.57510418 0.02870682 0.05130501]\n",
      " [0.07750964 0.0458731  0.06355313 ... 0.02645739 0.04789378 0.04527048]\n",
      " [0.03149243 0.02541135 0.03987177 ... 0.01983227 0.03192921 0.04823245]\n",
      " ...\n",
      " [0.07503084 0.04773756 0.056361   ... 0.02603549 0.04452708 0.04198694]\n",
      " [0.05067112 0.04383947 0.03706966 ... 0.04328064 0.03950184 0.14412674]\n",
      " [0.21417041 0.10781652 0.16465312 ... 0.09600972 0.17346799 0.20837526]]\n",
      "______________\n",
      "[14  3  6 14  1 15 14 13  2  5  1  8  7  8  5  3  7  2  3  8 11 16  0 14\n",
      " 12 16  4 10  3  6  0 15  9 11  5  0  7  7  3 13  0  9 12  8  8  6  3  7\n",
      "  4  2 10  2  7  1 16 12  5 16  5  1 12  6 16  0 10 12 16  2  6 16  0 10\n",
      " 13  7  0  8  6  0 12  0 16  0 11 12 13  7  4  0  2 11 14  6 14  6 14  4\n",
      "  6  0  0  2  2 12  5  9  6 15  1  7  6  3 14  2  2  1 12  4  6  8 15  7\n",
      "  2  3 16 16  1  2  6  5  2  0  5  2  0  3 14  0  0  6 12 14  0  1  7  2\n",
      "  2  3  1  0 14  6 14  4  8  3  5  7  0  0  3  2  1  9  3  4  2  5  1  9\n",
      " 15 11  0  9  6 10 10  0  4 13  0 14 11  7  2 14  2  3 12  8  5 15  6  2\n",
      " 10  0 12  1  0  1  1 11 15 15 15  0  2  2  7  3 11  2  1  2  3  2  9 12\n",
      "  1  5  3 11  0  0  8  1  2  4 16  9  3 15  0  0  9 15 13  0  7  7  6 12\n",
      " 16  0 13  0  0  7  3  5  6 16  0 10  0  2  0 10 13  3  3  1  0  7  1  0\n",
      " 12  2  8  8  2 14 10  2  3  0 14  7  5  9  0  4 10  0  0  6  0  3  3  6\n",
      " 14  6  6  0 11  7  1  8  5  3 12  3] [14  3  6 14  1  4 14 13  2  5  2 12  7  7  5  3 16  2  3 12 11 16  0 14\n",
      " 14  9 16 10 10  1  3 15  9 11  5 16  7  7  4 13 16 12 13 10 12 12  3  7\n",
      "  4  2 10  2 14  2 16 12  5 16  5  1 12  6  9  0 10 12 16  2  6  7 10 10\n",
      " 14  7  0 16  6  7 12  2  0 16 14 13 14  7  2  0  2 14 14  6 14  8 14  4\n",
      "  6 12 16 12  2 14 10 16  6 15 14  7 10  3 14  2 10  1 12  4  6 10 15 16\n",
      " 10  3  6 16 12  2  6  5  2 10  5  2 16  3 13  5 16  6 12 14 16  1  7 16\n",
      "  2  3  1 12 14 13 14  4 10  3  5  7 14  0 16  2  1  9  3  4  2  5 12  7\n",
      " 16 14  5  9 12 11 10  7 12 14  1 14  6  7 14 14  2  7 12 16  5 15  5  2\n",
      " 10 16 12  1 14 12  1 12 15 15 15  9  2  2 15  3  5  2  2 12  3  2  9 12\n",
      "  1  5  7 11  3  0 10 12  2  3 16  7  3 15 12  1  9 15 13 16  9  7 12 12\n",
      " 16 13 13 15 16 16  3  8 12 16  9 10  9  2 16 14 13  3  3  1  0  7 12 16\n",
      " 12  2  5  6  2 13 10  2  3  7 14  9  5  9  7  4 10 12  9 12 14  3  3  6\n",
      " 13  6  6 10 11  7  5  8  5  3 12  3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.056 MB of 0.056 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>LRAP</td><td>▁▅██</td></tr><tr><td>Training loss</td><td>█▁</td></tr><tr><td>accuracy</td><td>▁▅██</td></tr><tr><td>eval_loss</td><td>█▅▁▁</td></tr><tr><td>f1_macro</td><td>▁▄██</td></tr><tr><td>f1_micro</td><td>▁▅██</td></tr><tr><td>global_step</td><td>▁▂▃▆▆█</td></tr><tr><td>lr</td><td>▁▁</td></tr><tr><td>train_loss</td><td>▆█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>LRAP</td><td>0.85322</td></tr><tr><td>Training loss</td><td>0.3362</td></tr><tr><td>accuracy</td><td>0.58667</td></tr><tr><td>eval_loss</td><td>0.27804</td></tr><tr><td>f1_macro</td><td>0.57221</td></tr><tr><td>f1_micro</td><td>0.58667</td></tr><tr><td>global_step</td><td>128</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.13512</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cerulean-sweep-1</strong>: <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/3njx1x77\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/3njx1x77</a><br/>Synced 5 W&B file(s), 4 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220826_110226-3njx1x77\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: au8344sh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcustom_layer_parameters: [{'layer': 0, 'lr': 0}, {'layer': 1, 'lr': 0}, {'layer': 2, 'lr': 0}, {'layer': 3, 'lr': 0}, {'layer': 4, 'lr': 0}, {'layer': 5, 'lr': 0}, {'layer': 6, 'lr': 0}, {'layer': 7, 'lr': 0}, {'layer': 8, 'lr': 0}]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_batch_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 8.886410495041887e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tthreshold: 0.5475124227736768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.03782935256644958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\Transformers_simple_wandb_experiments\\SASDGHUB\\wandb\\run-20220826_111009-au8344sh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/au8344sh\" target=\"_blank\">stellar-sweep-2</a></strong> to <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/7o7g867l\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/7o7g867l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForMultiLabelSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForMultiLabelSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6918eb7deed94e9d964d36b5444c1db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_xlnet_128_0_2\n",
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d267e2fe136e4a07ba74a46ecb00bf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450badfd2a1643c081da458d59ad9321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763101c11a52434f97d751799b484c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.13938436 0.20195904 0.11044035 ... 0.14168438 0.10067342 0.16596925]\n",
      " [0.09908681 0.2420073  0.13065875 ... 0.1145144  0.0958562  0.12072241]\n",
      " [0.08825763 0.19402269 0.11679903 ... 0.12446387 0.08508791 0.1335593 ]\n",
      " ...\n",
      " [0.14699481 0.22299741 0.17889827 ... 0.11226662 0.09666228 0.11960766]\n",
      " [0.13356097 0.19844285 0.12426055 ... 0.13112065 0.13045999 0.16041401]\n",
      " [0.10634074 0.20541458 0.12693077 ... 0.12818284 0.11445989 0.15816215]]\n",
      "______________\n",
      "[14  3  6 14  1 15 14 13  2  5  1  8  7  8  5  3  7  2  3  8 11 16  0 14\n",
      " 12 16  4 10  3  6  0 15  9 11  5  0  7  7  3 13  0  9 12  8  8  6  3  7\n",
      "  4  2 10  2  7  1 16 12  5 16  5  1 12  6 16  0 10 12 16  2  6 16  0 10\n",
      " 13  7  0  8  6  0 12  0 16  0 11 12 13  7  4  0  2 11 14  6 14  6 14  4\n",
      "  6  0  0  2  2 12  5  9  6 15  1  7  6  3 14  2  2  1 12  4  6  8 15  7\n",
      "  2  3 16 16  1  2  6  5  2  0  5  2  0  3 14  0  0  6 12 14  0  1  7  2\n",
      "  2  3  1  0 14  6 14  4  8  3  5  7  0  0  3  2  1  9  3  4  2  5  1  9\n",
      " 15 11  0  9  6 10 10  0  4 13  0 14 11  7  2 14  2  3 12  8  5 15  6  2\n",
      " 10  0 12  1  0  1  1 11 15 15 15  0  2  2  7  3 11  2  1  2  3  2  9 12\n",
      "  1  5  3 11  0  0  8  1  2  4 16  9  3 15  0  0  9 15 13  0  7  7  6 12\n",
      " 16  0 13  0  0  7  3  5  6 16  0 10  0  2  0 10 13  3  3  1  0  7  1  0\n",
      " 12  2  8  8  2 14 10  2  3  0 14  7  5  9  0  4 10  0  0  6  0  3  3  6\n",
      " 14  6  6  0 11  7  1  8  5  3 12  3] [ 1  1  1  1  1  1  1  1  1  1  1 12  1  1  1  1 16  1  1  1  1  1  1  1\n",
      " 16  1 16  1  1  1  1  1  1  1  1  1  1  6  1  1  1  1  1  1 16  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  5  1  1 16 11  1  1  1  1  1  1 11 16 16  1\n",
      "  1  1  1  1  1  1  5  1  1  1  1  1 16  1  1  1  1 16  1  1  1  1  1  1\n",
      "  1  1  1  1  1 11  1  1  1  1  1  3  1  1  1  1  1  1 16  1 12  1  1  1\n",
      "  1  1  1  1  1  1  5  1  1  1 16  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1 11  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1 16  1  1  1  1  1  1 16  1  1  1  1  1  1  1  1  1 16  1  1  1  1  1\n",
      "  1  1 11  1 11  1  1  1  1  1  1  1  1  1  5  1  1  1  1  1  1  1  1  1\n",
      " 16  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1 16  1  1  1  1  1  1 16  1  1  1  1  1  9  1  1  1  1 16  1  1  1  1\n",
      "  1  1  1 12  1  1  1  1  1  1  1  1  1 16  1  1  1  1  1  1  1  1  1  1\n",
      " 16  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:simpletransformers.classification.classification_model:can't log value of type: <class 'wandb.viz.CustomChart'> to tensorboar\n",
      "INFO:simpletransformers.classification.classification_model: Training of xlnet model complete. Saved to outputs/.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b365dfddc2264e49bff38b4a1dbaf07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b435c04e1cc947f0af12b315dd50d696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'LRAP': 0.3064798474797297, 'accuracy': 0.06333333333333334, 'f1_macro': 0.011021566116843665, 'f1_micro': 0.06333333333333334, 'cm': <wandb.viz.CustomChart object at 0x0000023403BC7460>, 'eval_loss': 0.4246293629705906}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] [[0.13938436 0.20195904 0.11044035 ... 0.14168438 0.10067342 0.16596925]\n",
      " [0.09908681 0.2420073  0.13065875 ... 0.1145144  0.0958562  0.12072241]\n",
      " [0.08825763 0.19402269 0.11679903 ... 0.12446387 0.08508791 0.1335593 ]\n",
      " ...\n",
      " [0.14699481 0.22299741 0.17889827 ... 0.11226662 0.09666228 0.11960766]\n",
      " [0.13356097 0.19844285 0.12426055 ... 0.13112065 0.13045999 0.16041401]\n",
      " [0.10634074 0.20541458 0.12693077 ... 0.12818284 0.11445989 0.15816215]]\n",
      "______________\n",
      "[14  3  6 14  1 15 14 13  2  5  1  8  7  8  5  3  7  2  3  8 11 16  0 14\n",
      " 12 16  4 10  3  6  0 15  9 11  5  0  7  7  3 13  0  9 12  8  8  6  3  7\n",
      "  4  2 10  2  7  1 16 12  5 16  5  1 12  6 16  0 10 12 16  2  6 16  0 10\n",
      " 13  7  0  8  6  0 12  0 16  0 11 12 13  7  4  0  2 11 14  6 14  6 14  4\n",
      "  6  0  0  2  2 12  5  9  6 15  1  7  6  3 14  2  2  1 12  4  6  8 15  7\n",
      "  2  3 16 16  1  2  6  5  2  0  5  2  0  3 14  0  0  6 12 14  0  1  7  2\n",
      "  2  3  1  0 14  6 14  4  8  3  5  7  0  0  3  2  1  9  3  4  2  5  1  9\n",
      " 15 11  0  9  6 10 10  0  4 13  0 14 11  7  2 14  2  3 12  8  5 15  6  2\n",
      " 10  0 12  1  0  1  1 11 15 15 15  0  2  2  7  3 11  2  1  2  3  2  9 12\n",
      "  1  5  3 11  0  0  8  1  2  4 16  9  3 15  0  0  9 15 13  0  7  7  6 12\n",
      " 16  0 13  0  0  7  3  5  6 16  0 10  0  2  0 10 13  3  3  1  0  7  1  0\n",
      " 12  2  8  8  2 14 10  2  3  0 14  7  5  9  0  4 10  0  0  6  0  3  3  6\n",
      " 14  6  6  0 11  7  1  8  5  3 12  3] [ 1  1  1  1  1  1  1  1  1  1  1 12  1  1  1  1 16  1  1  1  1  1  1  1\n",
      " 16  1 16  1  1  1  1  1  1  1  1  1  1  6  1  1  1  1  1  1 16  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  5  1  1 16 11  1  1  1  1  1  1 11 16 16  1\n",
      "  1  1  1  1  1  1  5  1  1  1  1  1 16  1  1  1  1 16  1  1  1  1  1  1\n",
      "  1  1  1  1  1 11  1  1  1  1  1  3  1  1  1  1  1  1 16  1 12  1  1  1\n",
      "  1  1  1  1  1  1  5  1  1  1 16  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1 11  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1 16  1  1  1  1  1  1 16  1  1  1  1  1  1  1  1  1 16  1  1  1  1  1\n",
      "  1  1 11  1 11  1  1  1  1  1  1  1  1  1  5  1  1  1  1  1  1  1  1  1\n",
      " 16  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1 16  1  1  1  1  1  1 16  1  1  1  1  1  9  1  1  1  1 16  1  1  1  1\n",
      "  1  1  1 12  1  1  1  1  1  1  1  1  1 16  1  1  1  1  1  1  1  1  1  1\n",
      " 16  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.015 MB of 0.015 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>LRAP</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>f1_macro</td><td>▁</td></tr><tr><td>f1_micro</td><td>▁</td></tr><tr><td>global_step</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>LRAP</td><td>0.30648</td></tr><tr><td>accuracy</td><td>0.06333</td></tr><tr><td>eval_loss</td><td>0.42463</td></tr><tr><td>f1_macro</td><td>0.01102</td></tr><tr><td>f1_micro</td><td>0.06333</td></tr><tr><td>global_step</td><td>42</td></tr><tr><td>train_loss</td><td>0.31478</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stellar-sweep-2</strong>: <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/au8344sh\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/au8344sh</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220826_111009-au8344sh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p4ebpk4j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcustom_layer_parameters: [{'layer': 0, 'lr': 0}, {'layer': 1, 'lr': 0}, {'layer': 2, 'lr': 0}, {'layer': 3, 'lr': 0}, {'layer': 4, 'lr': 0}, {'layer': 5, 'lr': 0}, {'layer': 6, 'lr': 0}]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \teval_batch_size: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001380762768254618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_train_epochs: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tthreshold: 0.04710981724990448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_batch_size: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_steps: 94\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0426233077633745\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\Transformers_simple_wandb_experiments\\SASDGHUB\\wandb\\run-20220826_111248-p4ebpk4j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/p4ebpk4j\" target=\"_blank\">dandy-sweep-3</a></strong> to <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/7o7g867l\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/7o7g867l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForMultiLabelSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForMultiLabelSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df667d278ee4bed911ed9b3e9f883e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_xlnet_128_0_2\n",
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3972da69b2c48089322baeaad76d9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b10cdeb2d94fd6a14af786c13089c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional model configuration\n",
    "model_args = MultiLabelClassificationArgs(fp16= False,\n",
    "                                          manual_seed = 4,\n",
    "                                          use_multiprocessing = True,\n",
    "                                          overwrite_output_dir=True,\n",
    "                                          evaluate_during_training = True,\n",
    "                                          # save_model_every_epoch = False, \n",
    "                                          # save_steps=-1, # use this parameter and the next parameter to train on text of longer than 512 words in length\n",
    "                                          # sliding_window=True, # these parameters are bugged in this current version and will likely be updated soon\n",
    "                                         )\n",
    "\n",
    "# define the training function\n",
    "def train():\n",
    "    \n",
    "    # Initialize a new wandb run \n",
    "    wandb.init()\n",
    "\n",
    "    # Create a MultiLabelClassificationModel\n",
    "    model = MultiLabelClassificationModel(\n",
    "        \"xlnet\",\n",
    "        \"xlnet-base-cased\",\n",
    "        num_labels=label_count,\n",
    "        args=model_args,\n",
    "        use_cuda=cuda_available,\n",
    "        pos_weight=list((1/label_count)/class_weight),\n",
    "        # show_running_loss=True,\n",
    "        sweep_config=wandb.config,\n",
    "    )\n",
    "        \n",
    "    # Train the model\n",
    "    model.train_model(train_df,\n",
    "                      verbose=True,\n",
    "                      eval_df=eval_df,\n",
    "                      accuracy=acc_result,\n",
    "                      f1_macro=f1_macro_result,\n",
    "                      f1_micro=f1_micro_result,\n",
    "                      cm=cm_result)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(\n",
    "        eval_df,\n",
    "        verbose=True,\n",
    "        accuracy=acc_result,\n",
    "        f1_macro=f1_macro_result,\n",
    "        f1_micro=f1_micro_result,\n",
    "        cm=cm_result\n",
    "    )\n",
    "    \n",
    "    # Sync wandb\n",
    "    wandb.join()\n",
    "\n",
    "# run the sweep and record results in wandb    \n",
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
