{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a96a75d-3dab-421b-91cb-64fc77378b0e",
   "metadata": {},
   "source": [
    "# Apply and Test\n",
    "\n",
    "This script shows how the model can be applied when it has already been trained. It also shows how each target can be classified from the SDGs and an embedding model.\n",
    "\n",
    "Further this script shows how these classification models can be tested and evaluated on unseen data to get an estiamte of the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7deb845-3059-4a9a-a531-db0d3cf04e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:40:35.439560Z",
     "iopub.status.busy": "2022-09-02T00:40:35.439061Z",
     "iopub.status.idle": "2022-09-02T00:40:40.808176Z",
     "shell.execute_reply": "2022-09-02T00:40:40.807173Z",
     "shell.execute_reply.started": "2022-09-02T00:40:35.439061Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import itertools\n",
    "import sklearn\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585f395c-dd77-4b78-8fa8-375e1a3fd73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:40:40.811676Z",
     "iopub.status.busy": "2022-09-02T00:40:40.810674Z",
     "iopub.status.idle": "2022-09-02T00:40:40.885674Z",
     "shell.execute_reply": "2022-09-02T00:40:40.884673Z",
     "shell.execute_reply.started": "2022-09-02T00:40:40.811676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see GPU avaialability\n",
    "cuda_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e1c175-6bf5-4ba8-bcfd-5a431c7c52c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:40:40.887673Z",
     "iopub.status.busy": "2022-09-02T00:40:40.887673Z",
     "iopub.status.idle": "2022-09-02T00:40:41.877789Z",
     "shell.execute_reply": "2022-09-02T00:40:41.876789Z",
     "shell.execute_reply.started": "2022-09-02T00:40:40.887673Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GCM\\AppData\\Local\\Temp\\ipykernel_14396\\1824671989.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sdg_test_data['sdg_onehot'] = sdg_test_data[sdg_lst].values.tolist()\n"
     ]
    }
   ],
   "source": [
    "# import unseen data \n",
    "data = pd.read_csv('OneHot_Combined_cln_utf8.tsv', sep='\\t')\n",
    "sdg_test_data = data[data['source']=='SASDG_Hub']\n",
    "sdg_lst = ['SDG1','SDG2','SDG3','SDG4','SDG5','SDG6','SDG7','SDG8','SDG9','SDG10','SDG11','SDG12','SDG13','SDG14','SDG15','SDG16','SDG17']\n",
    "sdg_test_data['sdg_onehot'] = sdg_test_data[sdg_lst].values.tolist()\n",
    "sdg_test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "target_test_data = data[data['target'].notna()][['abstract', 'target']].reset_index(drop=True)\n",
    "target_test_text_lst = target_test_data['abstract'].tolist()\n",
    "\n",
    "# import target data\n",
    "target_df = pd.read_csv('Targets.csv', sep=';')\n",
    "targets_lst = target_df['target'].unique().tolist()\n",
    "sdg_lst = list(range(1,18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f510eee4-062c-49c9-ae33-b08af3fdb31c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:40:41.880288Z",
     "iopub.status.busy": "2022-09-02T00:40:41.879790Z",
     "iopub.status.idle": "2022-09-02T00:40:41.909288Z",
     "shell.execute_reply": "2022-09-02T00:40:41.907788Z",
     "shell.execute_reply.started": "2022-09-02T00:40:41.880288Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define data here\n",
    "eval_df = sdg_test_data[['abstract', 'sdg_onehot']]\n",
    "eval_df.columns = ['text', 'labels']\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# # use the threshold to adjust classifications (ROC curve?)\n",
    "# threshold_val=0.1\n",
    "\n",
    "# # Optional model configuration (all parameters defind in sweep config in parameter optimisation are now stated here)\n",
    "# model_args = MultiLabelClassificationArgs(use_multiprocessing = True,\n",
    "#                                           threshold=threshold_val, # see value above\n",
    "#                                           wandb_project = 'sasdghub_ml_classify',\n",
    "#                                           wandb_kwargs={\n",
    "#                                               'entity':'sasdghub'\n",
    "#                                                        }\n",
    "#                                          )\n",
    "\n",
    "# # import model from path (this path is the directory with all the model files)\n",
    "# sdg_model = MultiLabelClassificationModel(\n",
    "#         \"xlnet\",\n",
    "#         \"outputs/best_model/\",  \n",
    "#         num_labels=17,\n",
    "#         use_cuda=cuda_available,\n",
    "#         args=model_args,\n",
    "#         )\n",
    "\n",
    "# create functions for additional evaluation outputs\n",
    "def sdg_acc_result(true, pred):\n",
    "    pred=(pred>=wandb.config['threshold']).astype(int)\n",
    "    acc_sum = 0\n",
    "    for i in range(true.shape[0]):\n",
    "        acc_sum += sklearn.metrics.accuracy_score(true[i], pred[i])    \n",
    "    acc = acc_sum/true.shape[0]\n",
    "    return acc\n",
    "\n",
    "def sdg_f1_macro_result(true, pred):\n",
    "    pred=(pred>=wandb.config['threshold']).astype(int)\n",
    "    f1 = sklearn.metrics.f1_score(true, pred, average='samples')\n",
    "    return f1\n",
    "\n",
    "def sdg_cm_wandb_result(true, pred):\n",
    "    pred=(pred>=wandb.config['threshold']).astype(int)\n",
    "    # modify labels and fill all combinations to use wand multiclass confusion matrix visually\n",
    "    d=true-pred\n",
    "    t_d = (d==1)\n",
    "    p_d = (d==-1)\n",
    "    n_d = (d==0)\n",
    "    idx_ar = np.array(range(0,true.shape[1]))\n",
    "    idx = np.tile(idx_ar,true.shape[0]).reshape(true.shape[0],true.shape[1])\n",
    "    n_labels = idx[n_d]\n",
    "    t_lst = []\n",
    "    for row in t_d:\n",
    "        if row.sum()==0:\n",
    "            t_lst.append(idx_ar)\n",
    "        else:\n",
    "            t_lst.append(idx_ar[row])\n",
    "    p_lst = []\n",
    "    for row in p_d:\n",
    "        if row.sum()==0:\n",
    "            p_lst.append(idx_ar)\n",
    "        else:\n",
    "            p_lst.append(idx_ar[row])\n",
    "    for i in range(len(t_lst)):\n",
    "        fill_ar = np.array(list(itertools.product(p_lst[i], t_lst[i])))\n",
    "        t_labels = np.append(n_labels,fill_ar[:,0].tolist())\n",
    "        p_labels = np.append(n_labels,fill_ar[:,1].tolist())\n",
    "    wandb_cm = wandb.plot.confusion_matrix(probs=None, y_true=t_labels, preds=p_labels, class_names=sdg_lst)\n",
    "    return wandb_cm\n",
    "\n",
    "def sdg_cm_result(true, pred):\n",
    "    pred=(pred>=wandb.config['threshold']).astype(int)\n",
    "    cm = sklearn.metrics.multilabel_confusion_matrix(true, pred)\n",
    "    return cm\n",
    "\n",
    "def sdg_cm_avg_result(true, pred):\n",
    "    pred=(pred>=wandb.config['threshold']).astype(int)\n",
    "    cm = sklearn.metrics.multilabel_confusion_matrix(true, pred)\n",
    "    cm_avg = cm.sum(axis=0)/true.shape[1]\n",
    "    return cm_avg\n",
    "\n",
    "# # run sdg classification test\n",
    "# wandb.init()\n",
    "\n",
    "# # model evaluation\n",
    "# result, model_outputs, wrong_predictions = sdg_model.eval_model(\n",
    "#     verbose=True,\n",
    "#     eval_df=eval_df,\n",
    "#     accuracy=sdg_acc_result,\n",
    "#     f1_macro=sdg_f1_macro_result,\n",
    "#     cm=sdg_cm_result,\n",
    "#     cm_avg=sdg_cm_avg_result,\n",
    "#     wandb_cm=sdg_cm_wandb_result\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce1032c-6add-4e9f-8aeb-b8fa17f62a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:40:41.910789Z",
     "iopub.status.busy": "2022-09-02T00:40:41.910789Z",
     "iopub.status.idle": "2022-09-02T00:41:08.061111Z",
     "shell.execute_reply": "2022-09-02T00:41:08.059611Z",
     "shell.execute_reply.started": "2022-09-02T00:40:41.910789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wandb.agents.pyagent:Starting sweep agent: entity=None, project=None, count=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: pu5z05rt\n",
      "Sweep URL: https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/pu5z05rt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 44y0b1dl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tthreshold: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m (\u001b[33msasdghub\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\GIT_REPOS\\Transformers_simple_wandb_experiments\\SASDGHUB\\wandb\\run-20220901_204049-44y0b1dl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/44y0b1dl\" target=\"_blank\">misty-sweep-1</a></strong> to <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/pu5z05rt\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/pu5z05rt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba779e946b94bd79652a7d17e669fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43462904d3fa4b4e919bf7738f75a64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'LRAP': 0.7024627409627408, 'accuracy': 0.5385620915032678, 'f1_macro': 0.23198238614956884, 'cm': array([[[115,  96],\n",
      "        [  4,  10]],\n",
      "\n",
      "       [[ 78, 127],\n",
      "        [  0,  20]],\n",
      "\n",
      "       [[ 71,  76],\n",
      "        [  0,  78]],\n",
      "\n",
      "       [[ 92, 101],\n",
      "        [  1,  31]],\n",
      "\n",
      "       [[ 86, 132],\n",
      "        [  0,   7]],\n",
      "\n",
      "       [[ 70, 142],\n",
      "        [  1,  12]],\n",
      "\n",
      "       [[136,  75],\n",
      "        [  0,  14]],\n",
      "\n",
      "       [[115,  86],\n",
      "        [  1,  23]],\n",
      "\n",
      "       [[142,  71],\n",
      "        [  5,   7]],\n",
      "\n",
      "       [[ 52, 170],\n",
      "        [  0,   3]],\n",
      "\n",
      "       [[105,  89],\n",
      "        [  3,  28]],\n",
      "\n",
      "       [[145,  77],\n",
      "        [  1,   2]],\n",
      "\n",
      "       [[156,  65],\n",
      "        [  0,   4]],\n",
      "\n",
      "       [[152,  73],\n",
      "        [  0,   0]],\n",
      "\n",
      "       [[146,  73],\n",
      "        [  0,   6]],\n",
      "\n",
      "       [[ 82, 140],\n",
      "        [  0,   3]],\n",
      "\n",
      "       [[ 69, 156],\n",
      "        [  0,   0]]], dtype=int64), 'cm_avg': array([[106.58823529, 102.88235294],\n",
      "       [  0.94117647,  14.58823529]]), 'wandb_cm': <wandb.viz.CustomChart object at 0x000002B3CC9E1A00>, 'eval_loss': 0.22257878879706064}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misty-sweep-1</strong>: <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/44y0b1dl\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/44y0b1dl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220901_204049-44y0b1dl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use optimal parameters for function here\n",
    "# preferably use precalculated target_embedding_reduced_path\n",
    "sweep_config = {\n",
    "    \"name\" : \"sdg_test\",\n",
    "    \"method\": \"random\",\n",
    "    \"parameters\": {\n",
    "        \"threshold\": {\"value\": 0.1}, # use the threshold vlaue specified during training to make sure to get \n",
    "    },\n",
    "}\n",
    "\n",
    "# define the project and entity under which the outputs will be recorded in wandb\n",
    "sweep_id = wandb.sweep(sweep_config, entity='sasdghub', project=\"sasdghub_ml_classify\")\n",
    "\n",
    "# Set logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# define the training function\n",
    "def train():\n",
    "    \n",
    "    # Initialize a new wandb run \n",
    "    wandb.init()\n",
    "\n",
    "    # Create a MultiLabelClassificationModel\n",
    "    sdg_model = MultiLabelClassificationModel(\n",
    "            \"xlnet\",\n",
    "            \"outputs/best_model/\",  \n",
    "            num_labels=17,\n",
    "            use_cuda=cuda_available,\n",
    "            sweep_config=wandb.config\n",
    "            )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    result, model_outputs, wrong_predictions = sdg_model.eval_model(\n",
    "        verbose=True,\n",
    "        eval_df=eval_df,\n",
    "        accuracy=sdg_acc_result,\n",
    "        f1_macro=sdg_f1_macro_result,\n",
    "        cm=sdg_cm_result,\n",
    "        cm_avg=sdg_cm_avg_result,\n",
    "        wandb_cm=sdg_cm_wandb_result,\n",
    "        )\n",
    "    \n",
    "    # Sync wandb\n",
    "    wandb.join()\n",
    "\n",
    "# run the sweep and record results in wandb    \n",
    "wandb.agent(sweep_id, train,count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e70d3f-3cd3-460d-9286-e8e552754cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:41:08.063112Z",
     "iopub.status.busy": "2022-09-02T00:41:08.062613Z",
     "iopub.status.idle": "2022-09-02T00:41:08.076611Z",
     "shell.execute_reply": "2022-09-02T00:41:08.075110Z",
     "shell.execute_reply.started": "2022-09-02T00:41:08.063112Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to apply model to text\n",
    "def classify_sdg(text_lst):\n",
    "    # see GPU avaialability\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    \n",
    "    # import model from path (this path is the directory with all the model files)\n",
    "    sdg_model = MultiLabelClassificationModel(\n",
    "            \"xlnet\",\n",
    "            \"outputs/best_model/\",  \n",
    "            num_labels=17,\n",
    "            use_cuda=cuda_available,\n",
    "            )\n",
    "    predictions, raw_outputs = sdg_model.predict(text_lst)\n",
    "    return(predictions, raw_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31510a1c-eaa1-424a-95dd-fae0acf5e407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:41:08.080615Z",
     "iopub.status.busy": "2022-09-02T00:41:08.080111Z",
     "iopub.status.idle": "2022-09-02T00:41:08.277417Z",
     "shell.execute_reply": "2022-09-02T00:41:08.275917Z",
     "shell.execute_reply.started": "2022-09-02T00:41:08.080615Z"
    }
   },
   "outputs": [],
   "source": [
    "# make target predictions\n",
    "# target prediction requires SDG classification to already be done\n",
    "# function to classify targets\n",
    "def classify_sdg_target(text_lst,\n",
    "                        sdg_predictions,\n",
    "                        sdg_raw_outputs,\n",
    "                        target_data_path='Targets.csv',\n",
    "                        run_isomap=True, # run faster for multiple samples otherwise (target_data_path required when this is False) (do not use when only one sample)\n",
    "                        target_embedding_reduced_path=None, # load a previously calculated and reduced embedding for the targets 'outputs/targets_embedded_reduced_gpt2_2D.csv'\n",
    "                        isomap_dims = 2,\n",
    "                        isomap_neigbors = 5, # has to be <= len(text_lst) a.k.a n_samples\n",
    "                        pre_trained_model_type='gpt2', \n",
    "                        pre_trained_model_name='gpt2',\n",
    "                        target_threshold_val=0.5,\n",
    "                        ):\n",
    "    \n",
    "    \n",
    "\n",
    "    # define and load model from hugging face\n",
    "    model_args = ModelArgs(max_seq_length=1024)\n",
    "    # model import\n",
    "    model = RepresentationModel(\n",
    "        pre_trained_model_type,\n",
    "        pre_trained_model_name, #gpt2 , gpt2-large\n",
    "        args=model_args,\n",
    "    )    \n",
    "    \n",
    "    # get embeddings of text\n",
    "    word_embeddings = model.encode_sentences(text_lst, combine_strategy=\"mean\")\n",
    "    \n",
    "    \n",
    "    # ISOMAP\n",
    "    if run_isomap==True: \n",
    "        # reduce isomap_neigbors to fit the number of samples\n",
    "        n_samples = len(text_lst)\n",
    "        if n_samples < isomap_neigbors:\n",
    "            isomap_neigbors = np.max([1,n_samples-1])\n",
    "            print('Reduced isomap_n_neigbors to: ', isomap_neigbors)\n",
    "\n",
    "        # reduce dimensions of embeddings to 2 (can be reduced to higher dimensions)\n",
    "        isomap = Isomap(n_components=isomap_dims, n_neighbors=isomap_neigbors-1) # input is an array with samples x features\n",
    "        word_embeddings_transformed = isomap.fit_transform(word_embeddings)\n",
    "\n",
    "        if target_embedding_reduced_path == None:\n",
    "            # load pre-calculated embeddings\n",
    "            target_df = pd.read_csv(target_data_path, sep=';')\n",
    "            # get sentence list from target data\n",
    "            target_sentence_list = target_df['text'].tolist()\n",
    "            # get embeddings of targets\n",
    "            target_embeddings = model.encode_sentences(target_sentence_list, combine_strategy=\"mean\")\n",
    "            target_embeddings_transformed = isomap.fit_transform(target_embeddings)\n",
    "\n",
    "            # add labels to reduced embeddings\n",
    "            target_trans_df = pd.DataFrame(target_embeddings_transformed)\n",
    "            target_trans_df['target'] = target_df['target']\n",
    "            target_trans_df['sdg'] = target_df['sdg']\n",
    "            target_trans_df.to_csv('outputs/targets_embedded_reduced_'+pre_trained_model_name+'_'+str(isomap_dims)+'D.csv', index=False)\n",
    "\n",
    "            # define source and target for KNN\n",
    "            Y = target_trans_df\n",
    "            X = pd.DataFrame(word_embeddings_transformed)\n",
    "            idx_ar = np.array(range(0,17), np.int64)\n",
    "            sdg_label_lst = []\n",
    "            for row in (np.array(sdg_predictions)==1):\n",
    "                sdg_label_lst.append(idx_ar[row])\n",
    "            X['sdg'] = sdg_label_lst\n",
    "            sdg_prob_lst = []\n",
    "            for row in sdg_raw_outputs:\n",
    "                sdg_prob_lst.append(row)\n",
    "            X['sdg_probability'] = sdg_prob_lst\n",
    "            \n",
    "        else:\n",
    "            # import reduced embedding of targets\n",
    "            target_trans_df = pd.read_csv(target_embedding_reduced_path, sep=',')\n",
    "            \n",
    "            # define source and target for KNN\n",
    "            Y = target_trans_df\n",
    "            X = pd.DataFrame(word_embeddings_transformed)\n",
    "            idx_ar = np.array(range(0,17), np.int64)\n",
    "            sdg_label_lst = []\n",
    "            for row in (np.array(sdg_predictions)==1):\n",
    "                sdg_label_lst.append(idx_ar[row])\n",
    "            X['sdg'] = sdg_label_lst\n",
    "            sdg_prob_lst = []\n",
    "            for row in sdg_raw_outputs:\n",
    "                sdg_prob_lst.append(row)\n",
    "            X['sdg_probability'] = sdg_prob_lst\n",
    "\n",
    "        # plot embeddings if they are 2D\n",
    "        if isomap_dims ==2:\n",
    "            trans_df = pd.DataFrame(word_embeddings_transformed)\n",
    "            trans_df['target'] = target_df['target']\n",
    "            trans_df['sdg'] = target_df['sdg']\n",
    "            trans_df.plot.scatter(0,1,c='sdg', colormap='viridis') # colour by sdg\n",
    "            plt.title('Isomap 2D plot of text embedding')\n",
    "            plt.show()\n",
    "    \n",
    "    else:\n",
    "        # load pre-calculated embeddings\n",
    "        target_df = pd.read_csv(target_data_path, sep=';')\n",
    "        # get sentence list from target data\n",
    "        target_sentence_list = target_df['text'].tolist()\n",
    "        # get embeddings of targets\n",
    "        target_embeddings = model.encode_sentences(target_sentence_list, combine_strategy=\"mean\")\n",
    "        \n",
    "        # define source and target for KNN\n",
    "        Y = pd.DataFrame(target_embeddings)\n",
    "        Y['target'] = target_df['target']\n",
    "        Y['sdg'] = target_df['sdg']\n",
    "        X = pd.DataFrame(word_embeddings)\n",
    "        idx_ar = np.array(range(0,17), np.int64)\n",
    "        sdg_label_lst = []\n",
    "        for row in (np.array(sdg_predictions)==1):\n",
    "            sdg_label_lst.append(idx_ar[row])\n",
    "        X['sdg'] = sdg_label_lst\n",
    "        sdg_prob_lst = []\n",
    "        for row in sdg_raw_outputs:\n",
    "            sdg_prob_lst.append(row)\n",
    "        X['sdg_probability'] = sdg_prob_lst\n",
    "    \n",
    "    # use cosine similarity Kmeans variant to classify targets\n",
    "    # define final results table\n",
    "    results_df = pd.DataFrame()\n",
    "    results_df['text'] = text_lst\n",
    "    results_df['sdg'] = X['sdg']\n",
    "    results_df['sdg_probability'] = X['sdg_probability']\n",
    "    # calculate pairwise cosine similarity between targets and text list\n",
    "    similarity_ar = cosine_similarity(X.loc[:, ~X.columns.isin(['sdg', 'sdg_probability'])], \n",
    "                                  Y.loc[:, ~Y.columns.isin(['sdg', 'target'])],\n",
    "                                 )\n",
    "    results_df['target_similarity'] = similarity_ar.tolist()\n",
    "    # select targets on distance sdg and threshold\n",
    "    targets_ar = np.array(Y['target'])\n",
    "    targets_full_ar = np.tile(targets_ar, (len(text_lst), 1)) \n",
    "    sdg_ar = np.array(Y['sdg'])\n",
    "    sdg_full_ar = np.tile(sdg_ar, (len(text_lst), 1))\n",
    "    sdg_select_ar = np.array(X['sdg'])\n",
    "    \n",
    "    # select classified SDGs\n",
    "    sdg_onehot_lst = []\n",
    "    for i in range(len(sdg_full_ar)):\n",
    "        isin_ar = np.isin(sdg_full_ar[i], sdg_select_ar[i])\n",
    "        sdg_onehot_lst.append(isin_ar)\n",
    "    sdg_onehot_ar = np.vstack(sdg_onehot_lst)\n",
    "    target_onehot_ar = (similarity_ar>=target_threshold_val)*sdg_onehot_ar\n",
    "    target_label_lst = (targets_full_ar*target_onehot_ar).tolist()\n",
    "    results_df['target'] = [[ele for ele in sub if ele != ''] for sub in target_label_lst]\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47a357ad-aac1-4a85-a806-cbf3ad33e4d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:41:08.280417Z",
     "iopub.status.busy": "2022-09-02T00:41:08.279917Z",
     "iopub.status.idle": "2022-09-02T00:41:08.478448Z",
     "shell.execute_reply": "2022-09-02T00:41:08.477448Z",
     "shell.execute_reply.started": "2022-09-02T00:41:08.279917Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluation metrics for targets\n",
    "# create functions for additional evaluation outputs\n",
    "def acc_result(true, pred, class_lst):\n",
    "    one_hot = MultiLabelBinarizer(classes=class_lst)\n",
    "    pred=one_hot.fit_transform(pred)\n",
    "    true=one_hot.fit_transform(true)\n",
    "    acc_sum = 0\n",
    "    for i in range(true.shape[0]):\n",
    "        acc_sum += sklearn.metrics.accuracy_score(true[i], pred[i])    \n",
    "    acc = acc_sum/true.shape[0]\n",
    "    return acc\n",
    "\n",
    "def f1_macro_result(true, pred, class_lst):\n",
    "    one_hot = MultiLabelBinarizer(classes=class_lst)\n",
    "    pred=one_hot.fit_transform(pred)\n",
    "    true=one_hot.fit_transform(true)\n",
    "    f1 = sklearn.metrics.f1_score(true, pred, average='samples')\n",
    "    return f1\n",
    "\n",
    "def cm_wandb_result(true, pred, class_lst):\n",
    "    one_hot = MultiLabelBinarizer(classes=class_lst)\n",
    "    pred=one_hot.fit_transform(pred)\n",
    "    true=one_hot.fit_transform(true)\n",
    "    # modify labels and fill all combinations to use wand multiclass confusion matrix visually\n",
    "    d=true-pred\n",
    "    t_d = (d==1)\n",
    "    p_d = (d==-1)\n",
    "    n_d = (d==0)\n",
    "    idx_ar = np.array(range(0,true.shape[1]))\n",
    "    idx = np.tile(idx_ar,true.shape[0]).reshape(true.shape[0],true.shape[1])\n",
    "    n_labels = idx[n_d]\n",
    "    t_lst = []\n",
    "    for row in t_d:\n",
    "        if row.sum()==0:\n",
    "            t_lst.append(idx_ar)\n",
    "        else:\n",
    "            t_lst.append(idx_ar[row])\n",
    "    p_lst = []\n",
    "    for row in p_d:\n",
    "        if row.sum()==0:\n",
    "            p_lst.append(idx_ar)\n",
    "        else:\n",
    "            p_lst.append(idx_ar[row])\n",
    "    for i in range(len(t_lst)):\n",
    "        fill_ar = np.array(list(itertools.product(p_lst[i], t_lst[i])))\n",
    "        t_labels = np.append(n_labels,fill_ar[:,0].tolist())\n",
    "        p_labels = np.append(n_labels,fill_ar[:,1].tolist())\n",
    "    wandb_cm = wandb.plot.confusion_matrix(probs=None, y_true=t_labels, preds=p_labels, class_names=class_lst)\n",
    "    return wandb_cm\n",
    "\n",
    "def cm_result(true, pred, class_lst):\n",
    "    one_hot = MultiLabelBinarizer(classes=class_lst)\n",
    "    pred=one_hot.fit_transform(pred)\n",
    "    true=one_hot.fit_transform(true)\n",
    "    cm = sklearn.metrics.multilabel_confusion_matrix(true, pred)\n",
    "    return cm\n",
    "\n",
    "def cm_avg_result(true, pred, class_lst):\n",
    "    one_hot = MultiLabelBinarizer(classes=class_lst)\n",
    "    pred=one_hot.fit_transform(pred)\n",
    "    true=one_hot.fit_transform(true)\n",
    "    cm = sklearn.metrics.multilabel_confusion_matrix(true, pred)\n",
    "    cm_avg = cm.sum(axis=0)/true.shape[1]\n",
    "    return cm_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a34c7f3-7131-4bf1-bc4c-2be727d9cf36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T00:41:08.480452Z",
     "iopub.status.busy": "2022-09-02T00:41:08.480452Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 5rstiqj7\n",
      "Sweep URL: https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/5rstiqj7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dyjsme4v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tisomap_dims: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tisomap_neigbors: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trun_isomap: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttarget_threshold_val: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\GIT_REPOS\\Transformers_simple_wandb_experiments\\SASDGHUB\\wandb\\run-20220901_204112-dyjsme4v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/dyjsme4v\" target=\"_blank\">glorious-sweep-1</a></strong> to <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/5rstiqj7\" target=\"_blank\">https://wandb.ai/sasdghub/sasdghub_ml_classify/sweeps/5rstiqj7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7d9155a6be4b908e728e9776a413ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define data here\n",
    "val_data = target_test_data\n",
    "\n",
    "# use optimal parameters for function here\n",
    "# preferably use precalculated target_embedding_reduced_path\n",
    "sweep_config = {\n",
    "    \"name\" : \"sdg_target_test\",\n",
    "    \"method\": \"random\",  # bayes, grid, random\n",
    "    \"parameters\": {\n",
    "        \"run_isomap\": {\"value\": True},\n",
    "        \"isomap_dims\": {\"value\": 2},\n",
    "        \"isomap_neigbors\": {\"value\": 2},\n",
    "        \"target_threshold_val\": {\"value\": 0.7},\n",
    "    },\n",
    "}\n",
    "\n",
    "# define the project and entity under which the outputs will be recorded in wandb\n",
    "sweep_id = wandb.sweep(sweep_config, entity='sasdghub', project=\"sasdghub_ml_classify\")\n",
    "\n",
    "# Set logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# define the training function\n",
    "def train():\n",
    "    \n",
    "    # Initialize a new wandb run \n",
    "    wandb.init()\n",
    "    \n",
    "    # classify SDGs as input to classify targets\n",
    "    predictions, raw_outputs = classify_sdg(target_test_text_lst)\n",
    "    # use optimal parameters for function here\n",
    "    # preferably use precalculated target_embedding_reduced_path\n",
    "    results_df = classify_sdg_target(text_lst=target_test_text_lst,\n",
    "                                     sdg_predictions=predictions,\n",
    "                                     sdg_raw_outputs=raw_outputs,\n",
    "                                     target_data_path='Targets.csv',\n",
    "                                     run_isomap=wandb.config.run_isomap, # run faster for multiple samples otherwise (target_data_path required when this is False) (do not use when only one sample)\n",
    "                                     target_embedding_reduced_path=None, # load a previously calculated and reduced embedding for the targets 'outputs/targets_embedded_reduced_gpt2_2D.csv'\n",
    "                                     isomap_dims = wandb.config.isomap_dims,\n",
    "                                     isomap_neigbors = wandb.config.isomap_neigbors,\n",
    "                                     pre_trained_model_type='gpt2', \n",
    "                                     pre_trained_model_name='gpt2',\n",
    "                                     target_threshold_val=wandb.config.target_threshold_val,)\n",
    "\n",
    "    accuracy = acc_result(true=val_data['target'], pred=results_df['target'])\n",
    "    f1_macro = f1_macro_result(true=val_data['target'], pred=results_df['target'])\n",
    "    cm = cm_result(true=val_data['target'], pred=results_df['target'])\n",
    "    cm_avg = cm_avg_result(true=val_data['target'], pred=results_df['target'])\n",
    "    # cm_wandb = cm_wandb_result(true=val_data['target'], pred=results_df['target']) #very hard to see the confusion matrix\n",
    "    \n",
    "    print(\"accuracy\", accuracy)\n",
    "    print(\"f1_macro\", f1_macro)\n",
    "    \n",
    "    wandb.log({\"accuracy\": accuracy, \n",
    "               \"f1_macro\": f1_macro,\n",
    "               \"confusion_matrix\": cm,\n",
    "               \"confusion_matrix_average\": cm_avg,\n",
    "               \"confusion_matrix_wandb\": cm_wandb,\n",
    "               \"run_isomap\":wandb.config.run_isomap,\n",
    "               \"isomap_dims\":wandb.config.isomap_dims,\n",
    "               \"isomap_neigbors\":wandb.config.isomap_neigbors,\n",
    "               \"target_threshold_val\":wandb.config.target_threshold_val\n",
    "              })\n",
    "    \n",
    "    # Sync wandb\n",
    "    wandb.join()\n",
    "\n",
    "# run the sweep and record results in wandb    \n",
    "wandb.agent(sweep_id, train, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab328d7f-9680-4548-a2f7-4493d64ac61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the method for targets and use for the SDGs OR\n",
    "# enlarge the evaluation batch size to maximum with wandb/simple trasnfoemrers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d58cc-0a91-4fae-9686-838384dd1a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
