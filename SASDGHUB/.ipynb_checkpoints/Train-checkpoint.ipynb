{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecced938-c225-4f12-b565-3d73b9329857",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "this script is to train the model after the parameters have been optimised.\n",
    "The final model is output to the output directory in the current directory. This can be changed as described in the [Simple transformers docs](https://simpletransformers.ai/docs/installation/).\n",
    "THis script also shows how the target classification can be prepared/trained.\n",
    "\n",
    "### SDG Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee564013-69a3-4853-98fe-6c2a00844ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T03:12:16.789954Z",
     "iopub.status.busy": "2022-08-29T03:12:16.789954Z",
     "iopub.status.idle": "2022-08-29T03:12:21.444591Z",
     "shell.execute_reply": "2022-08-29T03:12:21.443591Z",
     "shell.execute_reply.started": "2022-08-29T03:12:16.789954Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43217174-039a-41fa-9ab1-0441bc061dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T03:12:21.446593Z",
     "iopub.status.busy": "2022-08-29T03:12:21.446593Z",
     "iopub.status.idle": "2022-08-29T03:12:21.476592Z",
     "shell.execute_reply": "2022-08-29T03:12:21.475590Z",
     "shell.execute_reply.started": "2022-08-29T03:12:21.446593Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see GPU avaialability\n",
    "cuda_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2410685e-4550-4080-aa6b-74b1cce94dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T03:12:21.477595Z",
     "iopub.status.busy": "2022-08-29T03:12:21.476592Z",
     "iopub.status.idle": "2022-08-29T03:12:22.419591Z",
     "shell.execute_reply": "2022-08-29T03:12:22.418588Z",
     "shell.execute_reply.started": "2022-08-29T03:12:21.477595Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% PER CLASS:\n",
      "\n",
      " SDG1      4.995375\n",
      "SDG2      4.687018\n",
      "SDG3      5.087882\n",
      "SDG4      3.669442\n",
      "SDG5      4.687018\n",
      "SDG6      5.026210\n",
      "SDG7      5.272895\n",
      "SDG8      6.259636\n",
      "SDG9      5.735430\n",
      "SDG10     5.550416\n",
      "SDG11     4.347826\n",
      "SDG12     5.889608\n",
      "SDG13    10.730805\n",
      "SDG14     5.365402\n",
      "SDG15     6.475486\n",
      "SDG16     5.550416\n",
      "SDG17    10.669134\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv('OneHot_Combined_cln_utf8.tsv', sep='\\t')\n",
    "data = data[data['source']!='SASDG_Hub'] #keep the articles classified by Willem separate as an unseen testing set\n",
    "data = data.iloc[-1000:,:] # select a small subset of the data (last 1000 rows)\n",
    "\n",
    "# reformat data\n",
    "sdg_lst = ['SDG1','SDG2','SDG3','SDG4','SDG5','SDG6','SDG7','SDG8','SDG9','SDG10','SDG11','SDG12','SDG13','SDG14','SDG15','SDG16','SDG17']\n",
    "data['y'] = data[sdg_lst].values.tolist()\n",
    "y = data['y']\n",
    "X = data['abstract']\n",
    "\n",
    "# plot ratio of data\n",
    "class_weight = (data[sdg_lst].sum()/ data[sdg_lst].sum().sum())\n",
    "print('% PER CLASS:\\n\\n', class_weight*100)\n",
    "data[sdg_lst].sum().plot.bar()\n",
    "\n",
    "# split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# add data to dataframes\n",
    "train_df = pd.DataFrame()\n",
    "train_df['text'] = X_train\n",
    "train_df['labels'] = y_train\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "eval_df = pd.DataFrame()\n",
    "eval_df['text'] = X_val\n",
    "eval_df['labels'] = y_val\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# get number of classes\n",
    "label_count = len(sdg_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583face1-70f2-44ad-a913-1d66137b0afc",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-08-29T03:12:22.421594Z",
     "iopub.status.busy": "2022-08-29T03:12:22.421594Z",
     "iopub.status.idle": "2022-08-29T03:18:10.776516Z",
     "shell.execute_reply": "2022-08-29T03:18:10.774524Z",
     "shell.execute_reply.started": "2022-08-29T03:12:22.421594Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForMultiLabelSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForMultiLabelSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab6816314654324b703a649663b404e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_xlnet_128_0_2\n",
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd3b5811d0a4a2188874cb01c16ecc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Initializing WandB run for training.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristopher-marais\u001b[0m (\u001b[33msasdghub\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\gcmar\\Desktop\\GIT_REPOS\\Transformers_simple_wandb_experiments\\SASDGHUB\\wandb\\run-20220828_231234-13g5hadg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify/runs/13g5hadg\" target=\"_blank\">trim-cosmos-429</a></strong> to <a href=\"https://wandb.ai/sasdghub/sasdghub_ml_classify\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f12c20c132b43f9aa2309a1b34d1b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76f0313868040e5a87feb0d10685a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b564b44b2cc3436b9d329a5c25d4acd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983ca238c1694b7ebbd6316181fc1b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d4b8a1a3344760afbed2d80d3ecd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74d3175ba6d4d11a364d9158532e4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_xlnet_128_0_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3255f781734adcb94fa1fae55c9a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 83>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cm_avg\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m                      \u001b[49m\u001b[43meval_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m                      \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macc_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mf1_macro\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf1_macro_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcm_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcm_avg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcm_avg_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     92\u001b[0m result, model_outputs, wrong_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval_model(\n\u001b[0;32m     93\u001b[0m     eval_df,\n\u001b[0;32m     94\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m     cm_avg\u001b[38;5;241m=\u001b[39mcm_avg_result\n\u001b[0;32m     99\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\simpletransformers\\classification\\multi_label_classification_model.py:304\u001b[0m, in \u001b[0;36mMultiLabelClassificationModel.train_model\u001b[1;34m(self, train_df, multi_label, eval_df, output_dir, show_running_loss, args, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    295\u001b[0m     train_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    303\u001b[0m ):\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtrain_model(\n\u001b[0;32m    305\u001b[0m         train_df,\n\u001b[0;32m    306\u001b[0m         multi_label\u001b[38;5;241m=\u001b[39mmulti_label,\n\u001b[0;32m    307\u001b[0m         eval_df\u001b[38;5;241m=\u001b[39meval_df,\n\u001b[0;32m    308\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[0;32m    309\u001b[0m         show_running_loss\u001b[38;5;241m=\u001b[39mshow_running_loss,\n\u001b[0;32m    310\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    311\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    313\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:621\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[1;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    612\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    613\u001b[0m     train_dataset,\n\u001b[0;32m    614\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mtrain_sampler,\n\u001b[0;32m    615\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_batch_size,\n\u001b[0;32m    616\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdataloader_num_workers,\n\u001b[0;32m    617\u001b[0m )\n\u001b[0;32m    619\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 621\u001b[0m global_step, training_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    622\u001b[0m     train_dataloader,\n\u001b[0;32m    623\u001b[0m     output_dir,\n\u001b[0;32m    624\u001b[0m     multi_label\u001b[38;5;241m=\u001b[39mmulti_label,\n\u001b[0;32m    625\u001b[0m     show_running_loss\u001b[38;5;241m=\u001b[39mshow_running_loss,\n\u001b[0;32m    626\u001b[0m     eval_df\u001b[38;5;241m=\u001b[39meval_df,\n\u001b[0;32m    627\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    629\u001b[0m )\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# model_to_save.save_pretrained(output_dir)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;66;03m# self.tokenizer.save_pretrained(output_dir)\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;66;03m# torch.save(self.args, os.path.join(output_dir, \"training_args.bin\"))\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:917\u001b[0m, in \u001b[0;36mClassificationModel.train\u001b[1;34m(self, train_dataloader, output_dir, multi_label, show_running_loss, eval_df, test_df, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    913\u001b[0m     loss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    914\u001b[0m         loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    915\u001b[0m     )  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_running_loss:\n\u001b[0;32m    920\u001b[0m     batch_iterator\u001b[38;5;241m.\u001b[39mset_description(\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mnum_train_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Running Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m9.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train with optimal parameters from parameter tunign results\n",
    "# logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# create function for creating layer learning rate dictionary\n",
    "# this is used for freezing the number of layers from the first layer -> x layer\n",
    "def create_custom_layer_dict_lst(x):    \n",
    "    # get list of number of layers\n",
    "    # layers_lst = [0]\n",
    "    # for i in model.get_named_parameters():\n",
    "    #     layers_lst.append(int(re.findall(r\"layer\\.(\\d+)\", i)[0]))\n",
    "    #     layers_lst = list(set(layers_lst))\n",
    "    # create dictionary of layers to freeze\n",
    "    layer_dict_lst = []\n",
    "    for i in range(x+1):\n",
    "        layer_dict_lst.append({'layer':i, 'lr':0.0})\n",
    "    return layer_dict_lst\n",
    "\n",
    "# set threshold value here to calculate metrics accurately\n",
    "threshold_val = 0.95\n",
    "\n",
    "# Optional model configuration (all parameters defind in sweep config in parameter optimisation are now stated here)\n",
    "model_args = MultiLabelClassificationArgs(fp16= False,\n",
    "                                          manual_seed = 4,\n",
    "                                          use_multiprocessing = True,\n",
    "                                          overwrite_output_dir=True,\n",
    "                                          evaluate_during_training = True,\n",
    "                                          num_train_epochs=5,\n",
    "                                          learning_rate=0.0001,\n",
    "                                          train_batch_size=20,\n",
    "                                          eval_batch_size=20,\n",
    "                                          warmup_steps=300,\n",
    "                                          weight_decay=0.09,\n",
    "                                          threshold=threshold_val,\n",
    "                                          custom_layer_parameters=create_custom_layer_dict_lst(0),\n",
    "                                          wandb_project = 'sasdghub_ml_classify',\n",
    "                                          wandb_kwargs={\n",
    "                                              'entity':'sasdghub'\n",
    "                                                       }\n",
    "                                         )\n",
    "\n",
    "# Create a MultiLabelClassificationModel\n",
    "model = MultiLabelClassificationModel(\n",
    "        \"xlnet\",\n",
    "        \"xlnet-base-cased\",\n",
    "        num_labels=label_count,\n",
    "        args=model_args,\n",
    "        use_cuda=cuda_available,\n",
    "        pos_weight=list((1/label_count)/class_weight),\n",
    ")\n",
    "\n",
    "# create functions for additional evaluation outputs\n",
    "def acc_result(true, pred):\n",
    "    pred=(pred>=threshold_val).astype(int)\n",
    "    acc_sum = 0\n",
    "    for i in range(true.shape[0]):\n",
    "        acc_sum += sklearn.metrics.accuracy_score(true[i], pred[i])    \n",
    "    acc = acc_sum/true.shape[0]\n",
    "    return acc\n",
    "\n",
    "def f1_macro_result(true, pred):\n",
    "    pred=(pred>=threshold_val).astype(int)\n",
    "    f1 = sklearn.metrics.f1_score(true, pred, average='samples')\n",
    "    return f1\n",
    "\n",
    "def cm_result(true, pred):\n",
    "    true_label = np.where(true==1)[1]\n",
    "    pred=(pred>=threshold_val).astype(int)\n",
    "    pred_label = np.where(pred==1)[1]\n",
    "    # wandb.plot.confusion_matrix(probs=None, y_true=true_label, preds=pred_label, class_names=sdg_lst)\n",
    "    cm = sklearn.metrics.multilabel_confusion_matrix(true, pred)\n",
    "    return cm\n",
    "\n",
    "def cm_avg_result(true, pred):\n",
    "    pred=(pred>=threshold_val).astype(int)\n",
    "    cm = sklearn.metrics.multilabel_confusion_matrix(true, pred)\n",
    "    cm_avg = cm.sum(axis=0)/true.shape[1]\n",
    "    return cm_avg\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df,\n",
    "                      verbose=True,\n",
    "                      eval_df=eval_df,\n",
    "                      accuracy=acc_result,\n",
    "                      f1_macro=f1_macro_result,\n",
    "                      cm=cm_result,\n",
    "                      cm_avg=cm_avg_result)\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(\n",
    "    eval_df,\n",
    "    verbose=True,\n",
    "    accuracy=acc_result,\n",
    "    f1_macro=f1_macro_result,\n",
    "    cm=cm_result,\n",
    "    cm_avg=cm_avg_result\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe1404-25dc-4cf5-af28-f875336bd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new samples ofr each misclassification. for absent ones and for missed ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d549a8c-2272-459d-a5c8-a8cb7dc9222b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T03:47:08.834907Z",
     "iopub.status.busy": "2022-08-29T03:47:08.834907Z",
     "iopub.status.idle": "2022-08-29T03:47:08.850908Z",
     "shell.execute_reply": "2022-08-29T03:47:08.849908Z",
     "shell.execute_reply.started": "2022-08-29T03:47:08.834907Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = np.random.randint(2, size=(300,17))\n",
    "p = np.random.randint(2, size=(300,17))\n",
    "diff_mask = t.sum(axis=1)!=p.sum(axis=1)\n",
    "d=t-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51f14f13-b781-40f6-ae7b-c98990b5f9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T03:50:03.345990Z",
     "iopub.status.busy": "2022-08-29T03:50:03.345990Z",
     "iopub.status.idle": "2022-08-29T03:50:03.356998Z",
     "shell.execute_reply": "2022-08-29T03:50:03.355992Z",
     "shell.execute_reply.started": "2022-08-29T03:50:03.345990Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_d = (d==1).astype(int)\n",
    "p_d = (d==-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78f43d88-d8bd-47c0-9ed4-b58333d4230a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T03:50:44.502666Z",
     "iopub.status.busy": "2022-08-29T03:50:44.502666Z",
     "iopub.status.idle": "2022-08-29T03:50:44.519670Z",
     "shell.execute_reply": "2022-08-29T03:50:44.519670Z",
     "shell.execute_reply.started": "2022-08-29T03:50:44.502666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e90c8-c22d-42d5-886d-72515821fc7d",
   "metadata": {},
   "source": [
    "### Target classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e0297-9b06-429a-aeeb-7741fcefbc9c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.782509Z",
     "iopub.status.idle": "2022-08-29T03:18:10.782509Z",
     "shell.execute_reply": "2022-08-29T03:18:10.782509Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.782509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from simpletransformers.config.model_args import ModelArgs\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f338d0-bc9e-48a5-858f-722857fb6e49",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.784507Z",
     "iopub.status.idle": "2022-08-29T03:18:10.784507Z",
     "shell.execute_reply": "2022-08-29T03:18:10.784507Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.784507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import target data\n",
    "target_df = pd.read_csv('Targets.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfaec27-c0f5-40c0-931b-4304f8e318ff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.786507Z",
     "iopub.status.idle": "2022-08-29T03:18:10.786507Z",
     "shell.execute_reply": "2022-08-29T03:18:10.786507Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.786507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define and download model from hugging face\n",
    "# model parameters\n",
    "model_args = ModelArgs(max_seq_length=1024)\n",
    "\n",
    "# model import\n",
    "model = RepresentationModel(\n",
    "    \"gpt2\",\n",
    "    \"gpt2\", #gpt2 , gpt2-large\n",
    "    args=model_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684fb42-facb-49a0-865b-0ea972e1a334",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.787506Z",
     "iopub.status.idle": "2022-08-29T03:18:10.788509Z",
     "shell.execute_reply": "2022-08-29T03:18:10.788509Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.788509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_list = target_df['text'].tolist()\n",
    "word_embeddings = model.encode_sentences(sentence_list, combine_strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6ce04-0bbd-4866-83e9-778dfc0e718a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.789507Z",
     "iopub.status.idle": "2022-08-29T03:18:10.789507Z",
     "shell.execute_reply": "2022-08-29T03:18:10.789507Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.789507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989f954-48e4-431f-ab18-5f57b7c46b9f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.790507Z",
     "iopub.status.idle": "2022-08-29T03:18:10.791512Z",
     "shell.execute_reply": "2022-08-29T03:18:10.791512Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.791512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "isomap = Isomap(n_components=2) # input is an array wiht samples x features\n",
    "word_embeddings_transformed = isomap.fit_transform(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cd069-6d41-4fe9-97ea-63884ae9eaf5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.792508Z",
     "iopub.status.idle": "2022-08-29T03:18:10.793511Z",
     "shell.execute_reply": "2022-08-29T03:18:10.793511Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.793511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans_df = pd.DataFrame(word_embeddings_transformed)\n",
    "trans_df['target'] = target_df['target']\n",
    "trans_df['sdg'] = target_df['sdg']\n",
    "trans_df.plot.scatter(0,1,c='sdg', colormap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d90bfc-5c30-4067-a332-2c53905c4722",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.794509Z",
     "iopub.status.idle": "2022-08-29T03:18:10.795510Z",
     "shell.execute_reply": "2022-08-29T03:18:10.794509Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.794509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e365a-4c03-4bcf-84cb-69eaf1f5f6ae",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.796509Z",
     "iopub.status.idle": "2022-08-29T03:18:10.797514Z",
     "shell.execute_reply": "2022-08-29T03:18:10.796509Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.796509Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix the acc metrics to be able to tolerate multitiple labels\n",
    "# https://stackoverflow.com/questions/17568612/how-to-make-numpy-argmax-return-all-occurrences-of-the-maximum\n",
    "# training might need another activation function\n",
    "# add for loops to calcualte accuracy for each isnance and add all up (same for all other metrics (17xN is the number of classifications made for confusion matrix))\n",
    "# save threshold value to include in the pred output \n",
    "# change threshold to list of numbers to learn a unique threshold for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d12fb9-53b1-4484-9fbd-2041a17f6273",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-29T03:18:10.799518Z",
     "iopub.status.idle": "2022-08-29T03:18:10.800514Z",
     "shell.execute_reply": "2022-08-29T03:18:10.799518Z",
     "shell.execute_reply.started": "2022-08-29T03:18:10.799518Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a list of target descriptions\n",
    "# get embeddings from GPT2 of the descriptions\n",
    "# perform ISOMAP on the data\n",
    "\n",
    "# TO APPLY\n",
    "# get GPT2 embedding of testing text\n",
    "# apply isomap\n",
    "#Classify SDG\n",
    "#limit targets to SDG related targets only\n",
    "# measure distance\n",
    "#use bayesian search to find best overall distance cutoff for classification to have highest classfication accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
